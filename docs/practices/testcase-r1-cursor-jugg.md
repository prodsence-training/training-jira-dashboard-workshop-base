# Round 1: Test Cases 生成結果

基於 Round 4 User Story 和 Round 1 Acceptance Criteria 生成的測試案例邏輯設計。

## 測試策略概述

### 測試分層架構
- **前端單元測試**: 元件渲染和互動邏輯
- **前端整合測試**: API 整合和資料流測試
- **後端 API 測試**: 端點功能和資料處理
- **系統整合測試**: 端到端使用者流程

### 測試資料準備
- **Mock 資料**: 模擬 Google Sheets 資料結構
- **測試環境**: Docker 容器化測試環境
- **資料隔離**: 每個測試使用獨立的測試資料

## ID-001: Sprint 進度與 BUG 監控

### 前端測試案例

#### TC-001-F1: Sprint 進度頁面渲染測試
**測試目標**: 驗證 Sprint 進度頁面正確渲染所有必要元素
**測試步驟**:
1. 準備包含多個 Story 和 Bug 的 Sprint mock 資料
2. 渲染 Sprint 進度元件
3. 驗證頁面顯示 Sprint 整體完成百分比
4. 驗證顯示各功能的 Bug 數量統計
5. 驗證顯示剩餘時間與 Sprint 結束時間對比

**預期結果**: 所有必要的 UI 元素都正確顯示

#### TC-001-F2: Bug 詳細資訊互動測試
**測試目標**: 驗證點擊 Bug 統計數字後的互動行為
**測試步驟**:
1. 準備包含 Bug 的功能資料
2. 模擬使用者點擊 Bug 統計數字
3. 驗證系統顯示 Bug 清單
4. 驗證顯示 Bug 嚴重程度和狀態
5. 驗證顯示 Bug 趨勢圖表

**預期結果**: 點擊互動正確觸發詳細資訊顯示

#### TC-001-F3: 無 Bug 情況顯示測試
**測試目標**: 驗證沒有 Bug 時的正確顯示
**測試步驟**:
1. 準備不包含 Bug 的 Sprint 資料
2. 渲染 Sprint 進度頁面
3. 驗證 Bug 數量顯示為 0
4. 驗證顯示 "目前沒有發現 Bug" 提示訊息

**預期結果**: 空狀態正確處理和顯示

### 後端測試案例

#### TC-001-B1: Sprint 進度資料 API 測試
**測試目標**: 驗證 Sprint 進度資料的正確計算和回傳
**測試步驟**:
1. 準備包含不同狀態 Story 的測試資料
2. 呼叫 Sprint 進度 API 端點
3. 驗證回傳的整體完成百分比計算正確
4. 驗證 Bug 統計數據正確
5. 驗證剩餘時間計算正確

**預期結果**: API 回傳正確的統計資料

#### TC-001-B2: Bug 統計 API 測試
**測試目標**: 驗證 Bug 統計資料的正確性
**測試步驟**:
1. 準備包含不同嚴重程度 Bug 的測試資料
2. 呼叫 Bug 統計 API 端點
3. 驗證各功能 Bug 數量統計正確
4. 驗證 Bug 嚴重程度分類正確
5. 驗證 Bug 趨勢資料計算正確

**預期結果**: Bug 統計資料準確無誤

## ID-002: 自定義狀態燃盡圖

### 前端測試案例

#### TC-002-F1: 燃盡圖渲染測試
**測試目標**: 驗證自定義狀態燃盡圖的正確渲染
**測試步驟**:
1. 準備包含自定義狀態設定的測試資料
2. 渲染燃盡圖元件
3. 驗證圖表基於自定義狀態顯示
4. 驗證剩餘工作量與理想燃盜線對比顯示
5. 驗證圖表時間軸正確

**預期結果**: 燃盡圖正確反映自定義狀態的工作完成狀況

#### TC-002-F2: 狀態切換互動測試
**測試目標**: 驗證不同完成狀態間的切換功能
**測試步驟**:
1. 準備支援多種狀態的測試資料
2. 模擬使用者切換完成狀態
3. 驗證圖表即時更新
4. 驗證對應狀態下的剩餘工作量正確顯示
5. 驗證時間軸保持不變

**預期結果**: 狀態切換功能正常運作

#### TC-002-F3: 無自定義狀態處理測試
**測試目標**: 驗證未設定自定義狀態時的預設行為
**測試步驟**:
1. 準備沒有自定義狀態設定的測試資料
2. 渲染燃盡圖頁面
3. 驗證顯示預設完成狀態
4. 驗證提供設定自定義狀態的選項
5. 驗證顯示說明文字

**預期結果**: 預設狀態正確處理，提供設定選項

### 後端測試案例

#### TC-002-B1: 燃盡圖資料計算 API 測試
**測試目標**: 驗證基於自定義狀態的燃盡圖資料計算
**測試步驟**:
1. 準備包含不同狀態變更的測試資料
2. 呼叫燃盡圖資料 API
3. 驗證基於自定義狀態的剩餘工作量計算
4. 驗證時間點資料的正確性
5. 驗證理想燃盡線計算

**預期結果**: 燃盡圖資料計算準確

## ID-003: 團隊成員任務監控

### 前端測試案例

#### TC-003-F1: 團隊監控頁面渲染測試
**測試目標**: 驗證團隊成員任務分配狀況的顯示
**測試步驟**:
1. 準備多個成員的任務分配資料
2. 渲染團隊監控頁面
3. 驗證顯示所有團隊成員的任務分配
4. 驗證顯示每個成員的最後更新時間
5. 驗證顯示任務狀態和進度

**預期結果**: 團隊監控資訊完整顯示

#### TC-003-F2: 需要協助識別測試
**測試目標**: 驗證長時間未更新任務的高亮顯示
**測試步驟**:
1. 準備包含長時間未更新任務的測試資料
2. 渲染團隊監控頁面
3. 驗證長時間未更新的任務被高亮顯示
4. 驗證顯示任務卡住的時間長度
5. 驗證提供聯絡同事的快速方式

**預期結果**: 需要協助的任務正確識別和高亮

#### TC-003-F3: 成員詳細資訊查看測試
**測試目標**: 驗證點擊成員後的詳細資訊顯示
**測試步驟**:
1. 準備特定成員的詳細任務資料
2. 模擬點擊該團隊成員
3. 驗證顯示詳細任務清單
4. 驗證顯示任務時間資訊
5. 驗證顯示任務優先級和預計完成時間

**預期結果**: 成員詳細資訊正確顯示

### 後端測試案例

#### TC-003-B1: 團隊任務資料 API 測試
**測試目標**: 驗證團隊成員任務資料的正確聚合
**測試步驟**:
1. 準備多個成員的任務資料
2. 呼叫團隊監控 API
3. 驗證每個成員的任務分配資料正確
4. 驗證最後更新時間計算正確
5. 驗證任務狀態聚合正確

**預期結果**: 團隊任務資料聚合準確

## ID-004: 個人任務更新時間監控

### 前端測試案例

#### TC-004-F1: 個人任務頁面渲染測試
**測試目標**: 驗證個人任務更新狀況的顯示
**測試步驟**:
1. 準備包含不同更新時間的個人任務資料
2. 渲染個人任務頁面
3. 驗證顯示所有分配任務的最後更新時間
4. 驗證顯示與當前日期的時間差距
5. 驗證長時間未更新任務的高亮顯示

**預期結果**: 個人任務更新狀況正確顯示

#### TC-004-F2: 被忽略任務警告測試
**測試目標**: 驗證超過 3 天未更新任務的警告顯示
**測試步驟**:
1. 準備包含超過 3 天未更新任務的資料
2. 查看該任務詳情
3. 驗證顯示警告訊息
4. 驗證顯示任務預期完成時間
5. 驗證提供快速更新任務狀態選項

**預期結果**: 被忽略任務正確識別並顯示警告

#### TC-004-F3: 正常更新任務顯示測試
**測試目標**: 驗證正常更新任務的顯示狀態
**測試步驟**:
1. 準備所有正常更新的任務資料
2. 查看任務列表
3. 驗證所有任務顯示為正常狀態
4. 驗證不顯示警告訊息
5. 驗證顯示任務進度百分比

**預期結果**: 正常任務狀態正確顯示

### 後端測試案例

#### TC-004-B1: 個人任務時間計算 API 測試
**測試目標**: 驗證個人任務更新時間的計算邏輯
**測試步驟**:
1. 準備包含不同更新時間的任務資料
2. 呼叫個人任務 API
3. 驗證時間差距計算正確
4. 驗證長時間未更新任務的識別
5. 驗證任務進度計算

**預期結果**: 任務時間計算邏輯正確

## ID-005: Story 測試完成狀況與 Bug 監控

### 前端測試案例

#### TC-005-F1: Story 品質監控頁面測試
**測試目標**: 驗證 Story 測試狀況和 Bug 監控的顯示
**測試步驟**:
1. 準備包含測試任務和 Bug 的 Story 資料
2. 渲染 Story 品質監控頁面
3. 驗證顯示每個 Story 的測試完成狀況
4. 驗證顯示 Bug 數量
5. 驗證顯示測試覆蓋率百分比

**預期結果**: Story 品質資訊完整顯示

#### TC-005-F2: Story 詳細測試資訊查看測試
**測試目標**: 驗證 Story 詳細測試資訊的展示
**測試步驟**:
1. 準備包含多個測試案例的 Story 資料
2. 點擊特定 Story
3. 驗證顯示所有測試案例清單
4. 驗證顯示測試案例執行狀態
5. 驗證顯示相關 Bug 詳細資訊

**預期結果**: Story 詳細測試資訊正確展示

#### TC-005-F3: 無測試任務處理測試
**測試目標**: 驗證沒有測試任務的 Story 處理
**測試步驟**:
1. 準備沒有測試任務的 Story 資料
2. 查看該 Story
3. 驗證顯示 "尚未設定測試任務" 訊息
4. 驗證提供新增測試任務選項
5. 驗證顯示品質風險警告

**預期結果**: 無測試任務情況正確處理

### 後端測試案例

#### TC-005-B1: Story 測試狀況統計 API 測試
**測試目標**: 驗證 Story 測試狀況的統計計算
**測試步驟**:
1. 準備包含不同測試狀態的 Story 資料
2. 呼叫 Story 品質監控 API
3. 驗證測試完成狀況統計正確
4. 驗證 Bug 數量統計正確
5. 驗證測試覆蓋率計算正確

**預期結果**: Story 測試統計資料準確

## ID-006: Sprint Bug 統計與趨勢分析

### 前端測試案例

#### TC-006-F1: Bug 統計頁面渲染測試
**測試目標**: 驗證 Bug 統計和趨勢圖表的顯示
**測試步驟**:
1. 準備包含多個 Bug 的 Sprint 資料
2. 渲染 Bug 統計頁面
3. 驗證顯示 Bug 總數統計
4. 驗證顯示按嚴重程度分類的 Bug 數量
5. 驗證顯示 Bug 趨勢圖表

**預期結果**: Bug 統計資訊完整顯示

#### TC-006-F2: Bug 趨勢分析查看測試
**測試目標**: 驗證 Bug 趨勢圖表的詳細資訊
**測試步驟**:
1. 準備包含多天 Bug 資料的測試資料
2. 查看 Bug 趨勢圖表
3. 驗證顯示每日新增 Bug 數量
4. 驗證顯示已解決 Bug 數量
5. 驗證顯示 Bug 解決時間趨勢

**預期結果**: Bug 趨勢分析正確顯示

#### TC-006-F3: Bug 數量異常處理測試
**測試目標**: 驗證 Bug 數量異常情況的處理
**測試步驟**:
1. 準備包含異常 Bug 數量的測試資料
2. 查看該天的詳細資訊
3. 驗證高亮顯示異常的 Bug 數量
4. 驗證顯示可能的原因分析
5. 驗證提供調整開發流程建議

**預期結果**: Bug 異常情況正確識別和處理

### 後端測試案例

#### TC-006-B1: Bug 統計與趨勢計算 API 測試
**測試目標**: 驗證 Bug 統計和趨勢資料的計算
**測試步驟**:
1. 準備包含時間序列的 Bug 資料
2. 呼叫 Bug 統計 API
3. 驗證 Bug 總數和分類統計正確
4. 驗證趨勢資料計算正確
5. 驗證異常檢測邏輯正確

**預期結果**: Bug 統計和趨勢計算準確

## ID-007: Story Subtask 完整性檢查

### 前端測試案例

#### TC-007-F1: Story Subtask 清單顯示測試
**測試目標**: 驗證 Story 完整 Subtask 清單的顯示
**測試步驟**:
1. 準備包含多個 Subtask 的 Story 資料
2. 點擊該 Story
3. 驗證顯示完整的 Subtask 清單
4. 驗證顯示每個 Subtask 的工作量估算
5. 驗證顯示 Subtask 的依賴關係

**預期結果**: Subtask 清單完整顯示

#### TC-007-F2: 無 Subtask 處理測試
**測試目標**: 驗證沒有 Subtask 的 Story 處理
**測試步驟**:
1. 準備沒有 Subtask 的 Story 資料
2. 點擊該 Story
3. 驗證顯示 "尚未設定 Subtask" 訊息
4. 驗證提供新增 Subtask 選項
5. 驗證顯示工作量估算提醒

**預期結果**: 無 Subtask 情況正確處理

#### TC-007-F3: Subtask 詳細資訊查看測試
**測試目標**: 驗證 Subtask 詳細資訊的顯示
**測試步驟**:
1. 準備包含詳細資訊的 Subtask 資料
2. 點擊特定 Subtask
3. 驗證顯示詳細描述
4. 驗證顯示工作量估算和實際耗時
5. 驗證顯示相關測試案例

**預期結果**: Subtask 詳細資訊正確顯示

### 後端測試案例

#### TC-007-B1: Story Subtask 關聯 API 測試
**測試目標**: 驗證 Story 和 Subtask 的關聯資料處理
**測試步驟**:
1. 準備包含 Subtask 關聯的 Story 資料
2. 呼叫 Story Subtask API
3. 驗證 Subtask 清單資料正確
4. 驗證工作量估算計算正確
5. 驗證依賴關係資料正確

**預期結果**: Story Subtask 關聯資料處理準確

## ID-008: 項目卡住時間與原因分析

### 前端測試案例

#### TC-008-F1: 項目監控頁面渲染測試
**測試目標**: 驗證項目卡住狀況的監控顯示
**測試步驟**:
1. 準備包含卡住項目的測試資料
2. 渲染項目監控頁面
3. 驗證顯示所有卡住項目清單
4. 驗證顯示每個項目的卡住時間長度
5. 驗證顯示可能的卡住原因分析

**預期結果**: 項目卡住狀況正確顯示

#### TC-008-F2: 項目卡住詳細原因查看測試
**測試目標**: 驗證項目卡住詳細原因的展示
**測試步驟**:
1. 準備包含詳細卡住原因的項目資料
2. 點擊卡住的項目
3. 驗證顯示詳細卡住原因
4. 驗證顯示相關阻礙因素
5. 驗證提供解決建議和介入選項

**預期結果**: 項目卡住詳細資訊正確展示

#### TC-008-F3: 正常項目顯示測試
**測試目標**: 驗證正常進行項目的顯示狀態
**測試步驟**:
1. 準備所有正常進行的項目資料
2. 查看項目列表
3. 驗證所有項目顯示為正常狀態
4. 驗證不顯示卡住警告
5. 驗證顯示項目正常進度

**預期結果**: 正常項目狀態正確顯示

### 後端測试案例

#### TC-008-B1: 項目卡住分析 API 測試
**測試目標**: 驗證項目卡住時間和原因的分析邏輯
**測試步驟**:
1. 準備包含不同狀態變更的項目資料
2. 呼叫項目監控 API
3. 驗證卡住時間計算正確
4. 驗證卡住原因分析邏輯
5. 驗證解決建議生成

**預期結果**: 項目卡住分析邏輯正確

## 測試執行策略

### 測試環境準備
1. **Docker 環境啟動**: `make workshop-start`
2. **資料庫初始化**: 載入測試專用的 Google Sheets 資料
3. **API 服務確認**: 確保所有 API 端點正常運作

### 測試執行順序
1. **後端 API 測試**: 先確保資料層和業務邏輯正確
2. **前端單元測試**: 驗證元件獨立功能
3. **前端整合測試**: 驗證與 API 的整合
4. **端到端測試**: 驗證完整使用者流程

### 測試資料管理
- **獨立測試資料**: 每個測試使用隔離的測試資料
- **資料清理**: 測試後自動清理產生的資料
- **邊界條件覆蓋**: 包含空資料、極值資料的測試案例

### 測試覆蓋率目標
- **前端元件**: 80% 以上覆蓋率
- **後端 API**: 90% 以上覆蓋率
- **業務邏輯**: 100% 覆蓋關鍵業務流程

## 測試工具和框架

### 前端測試工具
- **Jest**: 測試框架
- **React Testing Library**: 元件測試
- **jest-dom**: DOM 匹配器
- **MSW**: API Mock 服務

### 後端測試工具  
- **pytest**: 測試框架
- **pytest-asyncio**: 非同步測試
- **httpx**: HTTP 客戶端測試
- **pytest-mock**: Mock 功能

### 持續整合
- **自動化測試**: 每次 commit 觸發測試
- **測試報告**: 生成詳細的測試覆蓋率報告
- **失敗通知**: 測試失敗時即時通知開發者

## 品質保證檢查點

### 功能完整性
- ✅ 所有 User Story 都有對應的測試案例
- ✅ 涵蓋 Acceptance Criteria 中的所有場景
- ✅ 包含正常流程、邊界條件和異常情況
- ✅ 符合現有系統技術能力

### 可維護性
- ✅ 測試案例結構清晰，易於理解
- ✅ 測試資料準備邏輯可重複使用
- ✅ 測試失敗時提供明確的錯誤資訊
- ✅ 測試執行效率高，避免不必要的等待

### 可靠性
- ✅ 測試結果一致性，避免隨機失敗
- ✅ 測試之間相互獨立，無依賴關係
- ✅ 模擬真實使用情境，測試結果有意義
- ✅ 覆蓋系統限制和約束條件
